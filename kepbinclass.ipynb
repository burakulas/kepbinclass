{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kepbinclass.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
        {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WGdIJa_PJDKF",
        "outputId": "ba11b490-7679-46fe-996c-5eadfb73d89e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "'''\n",
        "KEPBINCLASS----\n",
        "\n",
        "This script predicts the morphological class of the Kepler binary star \n",
        "systems through deep learning algorithm and recognizing their light \n",
        "curve images.\n",
        "\n",
        "Change the path of train and validation data directory values based your \n",
        "directory scheme. \n",
        "\n",
        "The script works on Python 3.x. Some modifications are needed to get it \n",
        "run in Python 2.x\n",
        "\n",
        "The script uses TensorFlow 1.x. Some modifications are needed to get it \n",
        "run in TensorFlow 2.x\n",
        "'''\n",
        "\n",
        "# import necessary modules\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras import backend as K\n",
        "from keras import regularizers\n",
        "from keras import optimizers\n",
        "from google.colab import files\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(2)\n",
        "\n",
        "# pass deprecated warnings from TF 2.0\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "\n",
        "\n",
        "img_width, img_height = 640, 480 # size of images\n",
        "\n",
        "# train and validation directory\n",
        "train_data_dir = 'drive/My Drive/newbin/newdata2/train'\n",
        "validation_data_dir = 'drive/My Drive/newbin/newdata2/validation'\n",
        "n_train = 1458 # number of train images\n",
        "n_valid = 294 # number of validation images\n",
        "epoch = 50 # number of epochs\n",
        "batch = 16 # batch size\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    input_shape = (3, img_width, img_height)\n",
        "else:\n",
        "    input_shape = (img_width, img_height, 3)\n",
        "\n",
        "\n",
        "# the model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001),\n",
        "                 input_shape=input_shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(3))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# augmentation configuration\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch,\n",
        "    class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch,\n",
        "    class_mode='categorical')\n",
        "\n",
        "\n",
        "#fitting\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=n_train // batch,\n",
        "    epochs=epoch,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=n_valid // batch, shuffle=False)\n",
        "\n",
        "\n",
        "#saving model\n",
        "\n",
        "model.save_weights('mod_binclass.h5')\n",
        "\n",
        "\n",
        "# plotting and saving the accuracy and loss function\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "plt.plot(epochs, acc, 'b', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.savefig('acc.png')\n",
        "plt.show()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.savefig('loss.png')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Prediction - a specific file\n",
        "\n",
        "img_width, img_height = 640, 480\n",
        "img = image.load_img('drive/My Drive/newbin/newdata2/pred/co1.png', \n",
        "                     target_size = (img_width, img_height))\n",
        "img = image.img_to_array(img)\n",
        "img = np.expand_dims(img, axis = 0)\n",
        "\n",
        "pred = model.predict_classes(img) # class prediction\n",
        "#pred = model.predict_proba(img) # probability prediction\n",
        "print(\"---Prediction-----\")\n",
        "print(pred)\n",
        "\n",
        "\n",
        "# Prediction - a bunch of images in folder\n",
        "\n",
        "pred_data_dir = 'drive/My Drive/newbin/newdata2/pred'\n",
        "\n",
        "images = []\n",
        "for img in os.listdir(pred_data_dir):\n",
        "    imgn = img\n",
        "    img = os.path.join(pred_data_dir, img)\n",
        "    img = image.load_img(img, target_size=(img_width, img_height))\n",
        "    img = image.img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = img / 255\n",
        "    classp = model.predict_classes(img)\n",
        "    print(imgn,classp) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1458 images belonging to 3 classes.\n",
            "Found 294 images belonging to 3 classes.\n",
            "Epoch 1/50\n",
            "91/91 [==============================] - 89s 983ms/step - loss: 0.7950 - acc: 0.8365 - val_loss: 0.4352 - val_acc: 0.8750\n",
            "Epoch 2/50\n",
            "91/91 [==============================] - 89s 975ms/step - loss: 0.2596 - acc: 0.9225 - val_loss: 0.1671 - val_acc: 0.9532\n",
            "Epoch 3/50\n",
            "91/91 [==============================] - 88s 967ms/step - loss: 0.2003 - acc: 0.9430 - val_loss: 0.2869 - val_acc: 0.9065\n",
            "Epoch 4/50\n",
            "91/91 [==============================] - 87s 956ms/step - loss: 0.1839 - acc: 0.9533 - val_loss: 0.1551 - val_acc: 0.9532\n",
            "Epoch 5/50\n",
            "91/91 [==============================] - 87s 954ms/step - loss: 0.1632 - acc: 0.9526 - val_loss: 0.1453 - val_acc: 0.9568\n",
            "Epoch 6/50\n",
            "91/91 [==============================] - 89s 979ms/step - loss: 0.1492 - acc: 0.9588 - val_loss: 0.1602 - val_acc: 0.9568\n",
            "Epoch 7/50\n",
            "91/91 [==============================] - 92s 1s/step - loss: 0.1587 - acc: 0.9663 - val_loss: 0.1402 - val_acc: 0.9532\n",
            "Epoch 8/50\n",
            "91/91 [==============================] - 96s 1s/step - loss: 0.1395 - acc: 0.9650 - val_loss: 0.2024 - val_acc: 0.9245\n",
            "Epoch 9/50\n",
            "91/91 [==============================] - 92s 1s/step - loss: 0.1524 - acc: 0.9595 - val_loss: 0.1811 - val_acc: 0.9424\n",
            "Epoch 10/50\n",
            "91/91 [==============================] - 91s 997ms/step - loss: 0.1200 - acc: 0.9712 - val_loss: 0.1621 - val_acc: 0.9604\n",
            "Epoch 11/50\n",
            "91/91 [==============================] - 90s 992ms/step - loss: 0.1329 - acc: 0.9691 - val_loss: 0.1702 - val_acc: 0.9460\n",
            "Epoch 12/50\n",
            "91/91 [==============================] - 90s 988ms/step - loss: 0.1284 - acc: 0.9670 - val_loss: 0.0901 - val_acc: 0.9820\n",
            "Epoch 13/50\n",
            "91/91 [==============================] - 91s 995ms/step - loss: 0.1055 - acc: 0.9760 - val_loss: 0.1863 - val_acc: 0.9604\n",
            "Epoch 14/50\n",
            "91/91 [==============================] - 90s 993ms/step - loss: 0.1192 - acc: 0.9698 - val_loss: 0.1756 - val_acc: 0.9388\n",
            "Epoch 15/50\n",
            "91/91 [==============================] - 90s 986ms/step - loss: 0.1224 - acc: 0.9712 - val_loss: 0.1570 - val_acc: 0.9568\n",
            "Epoch 16/50\n",
            "91/91 [==============================] - 90s 986ms/step - loss: 0.1242 - acc: 0.9663 - val_loss: 0.1329 - val_acc: 0.9640\n",
            "Epoch 17/50\n",
            "91/91 [==============================] - 90s 989ms/step - loss: 0.1152 - acc: 0.9718 - val_loss: 0.0994 - val_acc: 0.9820\n",
            "Epoch 18/50\n",
            "91/91 [==============================] - 89s 981ms/step - loss: 0.1042 - acc: 0.9732 - val_loss: 0.1082 - val_acc: 0.9784\n",
            "Epoch 19/50\n",
            "91/91 [==============================] - 89s 980ms/step - loss: 0.0885 - acc: 0.9760 - val_loss: 0.1442 - val_acc: 0.9568\n",
            "Epoch 20/50\n",
            "91/91 [==============================] - 90s 985ms/step - loss: 0.1154 - acc: 0.9643 - val_loss: 0.1378 - val_acc: 0.9653\n",
            "Epoch 21/50\n",
            "91/91 [==============================] - 91s 997ms/step - loss: 0.0789 - acc: 0.9828 - val_loss: 0.1309 - val_acc: 0.9640\n",
            "Epoch 22/50\n",
            "91/91 [==============================] - 90s 984ms/step - loss: 0.0945 - acc: 0.9794 - val_loss: 0.1267 - val_acc: 0.9712\n",
            "Epoch 23/50\n",
            "91/91 [==============================] - 89s 982ms/step - loss: 0.1060 - acc: 0.9712 - val_loss: 0.1105 - val_acc: 0.9676\n",
            "Epoch 24/50\n",
            "91/91 [==============================] - 90s 990ms/step - loss: 0.0922 - acc: 0.9760 - val_loss: 0.1487 - val_acc: 0.9640\n",
            "Epoch 25/50\n",
            "91/91 [==============================] - 90s 985ms/step - loss: 0.0995 - acc: 0.9753 - val_loss: 0.1015 - val_acc: 0.9820\n",
            "Epoch 26/50\n",
            "91/91 [==============================] - 90s 985ms/step - loss: 0.0972 - acc: 0.9725 - val_loss: 0.1193 - val_acc: 0.9712\n",
            "Epoch 27/50\n",
            "91/91 [==============================] - 89s 983ms/step - loss: 0.0747 - acc: 0.9787 - val_loss: 0.1361 - val_acc: 0.9532\n",
            "Epoch 28/50\n",
            "91/91 [==============================] - 89s 983ms/step - loss: 0.0802 - acc: 0.9760 - val_loss: 0.1408 - val_acc: 0.9712\n",
            "Epoch 29/50\n",
            "90/91 [============================>.] - ETA: 0s - loss: 0.0924 - acc: 0.9729"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yy9WJ5bMYZ0x",
        "colab_type": "code",
        "outputId": "a614fa7b-2e2c-4c7b-ac19-8029084dcb5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.15.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    }
  ]
}
