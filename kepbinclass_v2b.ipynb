{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kepbinclass_tf2_github.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/burakulas/kepbinclass/blob/master/kepbinclass_v2b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTQT7DsXqoKu",
        "colab_type": "code",
        "outputId": "42acf897-961e-40b8-cbff-397476474778",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# check the version of TensorFlow\n",
        "from packaging import version\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "print(\"TensorFlow version: \", tf.__version__)\n",
        "assert version.parse(tf.__version__).release[0] >= 2, \\\n",
        "    \"This notebook requires TensorFlow 2.0.\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow version:  2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwYwNKFXrOAX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import necessary modules\n",
        "import numpy as np\n",
        "from numpy.random import seed\n",
        "seed(42)#for repoductivity\n",
        "import random as rn\n",
        "rn.seed(12345)#\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow\n",
        "tensorflow.random.set_seed(1234)#rp\n",
        "import os\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
        "session_conf = tensorflow.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1) #rp\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import optimizers\n",
        "from google.colab import files\n",
        "\n",
        "tensorflow.compat.v1.set_random_seed(1234) #rp\n",
        "\n",
        "sess = tensorflow.compat.v1.Session(graph=tensorflow.compat.v1.get_default_graph(), config=session_conf) #rp\n",
        "tensorflow.compat.v1.keras.backend.set_session(sess) #rp\n",
        "\n",
        "img_width, img_height = 640, 480 # size of images\n",
        "\n",
        "# train and validation directory\n",
        "train_data_dir = 'drive/My Drive/newbin/newdata2/train'\n",
        "validation_data_dir = 'drive/My Drive/newbin/newdata2/validation'\n",
        "n_train = 1458 # number of train images\n",
        "n_valid = 294 # number of validation images\n",
        "epoch = 50 # number of epochs\n",
        "batch = 16 # batch size\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    input_shape = (3, img_width, img_height)\n",
        "else:\n",
        "    input_shape = (img_width, img_height, 3)\n",
        "\n",
        "# the model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3))) \n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(3))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# augmentation configuration\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch,\n",
        "    class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch,\n",
        "    class_mode='categorical')\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=n_train // batch,\n",
        "    epochs=epoch,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=n_valid // batch, shuffle=False)\n",
        "\n",
        "#saving model\n",
        "\n",
        "model.save('drive/My Drive/newbin/model/mod_kepbinclass.h5')\n",
        "\n",
        "# Prediction - a specific file\n",
        "\n",
        "img_width, img_height = 640, 480\n",
        "img = image.load_img('drive/My Drive/newbin/newdata2/pred/co1.png', \n",
        "                     target_size = (img_width, img_height))\n",
        "img = image.img_to_array(img)\n",
        "img = np.expand_dims(img, axis = 0)\n",
        "\n",
        "pred = model.predict_classes(img) # class prediction\n",
        "#pred = model.predict_proba(img) # probability prediction\n",
        "print(\"---Prediction-----\")\n",
        "print(pred)\n",
        "\n",
        "# Prediction - images in a folder\n",
        "\n",
        "pred_data_dir = 'drive/My Drive/newbin/newdata2/pred'\n",
        "\n",
        "images = []\n",
        "for img in os.listdir(pred_data_dir):\n",
        "    imgn = img\n",
        "    img = os.path.join(pred_data_dir, img)\n",
        "    img = image.load_img(img, target_size=(img_width, img_height))\n",
        "    img = image.img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = img / 255\n",
        "    classp = model.predict_classes(img)\n",
        "    print(imgn,classp)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}